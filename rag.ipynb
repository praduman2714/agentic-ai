{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81966b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9959d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\")\n",
    "model = ChatOllama(\n",
    "        model=OLLAMA_MODEL,\n",
    "        base_url=OLLAMA_HOST,\n",
    "        temperature=0.2,        # critical for factual stability\n",
    "        # num_predict=800,        # max tokens to generate\n",
    "        timeout=60              # avoid hanging workers\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1627ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"/home/pradumansingh/Desktop/Agentic/intro-to-ml.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7df3b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c47244e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = splitter.split_documents(docs)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90d263f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "EMBED_MODEL = \"qwen3-embedding:latest\"\n",
    "\n",
    "ollama_embedder = OllamaEmbeddings(\n",
    "    model=EMBED_MODEL)\n",
    "\n",
    "vectorstore = FAISS.from_documents(texts, ollama_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e10e6332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x7daf4e19b410>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "885a844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ddf3cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "@tool\n",
    "def rag_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant information from the pdf document.\n",
    "    \"\"\"\n",
    "    result = retriever.invoke(query)\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"[Page {doc.metadata.get('page', 'N/A')}]\\n{doc.page_content}\"\n",
    "        for doc in result\n",
    "    )\n",
    "\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed7e2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [rag_tool]\n",
    "tool_node = ToolNode(tools)\n",
    "llm_with_tools = model.bind(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f6cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee16e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class InputType(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b2bdb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, SystemMessage\n",
    "def chat_node(state: InputType, config=None):\n",
    "    \"\"\"LLM node that may answer or request a tool call.\"\"\"\n",
    "    thread_id = None\n",
    "    if config and isinstance(config, dict):\n",
    "        thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
    "\n",
    "    system_message = SystemMessage(\n",
    "        content=(\n",
    "            \"You are a helpful assistant. For questions about the uploaded PDF, call \"\n",
    "            \"the `rag_tool` and include the thread_id \"\n",
    "            f\"`{thread_id}`. You can also use the web search, stock price, and \"\n",
    "            \"calculator tools when helpful. If no document is available, ask the user \"\n",
    "            \"to upload a PDF.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    messages = [system_message, *state[\"messages\"]]\n",
    "    response = llm_with_tools.invoke(messages, config=config)\n",
    "    return {\"messages\": [response]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af265c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e9d75105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7daf2540c4a0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "graph = StateGraph(InputType)\n",
    "\n",
    "graph.add_node('chat_node', chat_node)\n",
    "graph.add_node('tools', tool_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_conditional_edges(\"chat_node\", tools_condition)\n",
    "\n",
    "\n",
    "graph.add_edge('tools', 'chat_node')\n",
    "\n",
    "chatbot = graph.compile(checkpointer=checkpointer)\n",
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6391911a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Tool\n  Input should be a valid dictionary or instance of Tool [type=model_type, input_value=StructuredTool(name='rag_...tool at 0x7daf25637ba0>), input_type=StructuredTool]\n    For further information visit https://errors.pydantic.dev/2.12/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_input.lower() \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBot:\u001b[39m\u001b[33m\"\u001b[39m, result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mchat_node\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m      8\u001b[39m system_message = SystemMessage(\n\u001b[32m      9\u001b[39m     content=(\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant. For questions about the uploaded PDF, call \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     )\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m messages = [system_message, *state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5557\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5550\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5555\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5556\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5558\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5560\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_ollama/chat_models.py:1030\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1025\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m     **kwargs: Any,\n\u001b[32m   1029\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m   1034\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m   1035\u001b[39m         message=AIMessage(\n\u001b[32m   1036\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1043\u001b[39m         generation_info=generation_info,\n\u001b[32m   1044\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_ollama/chat_models.py:965\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    957\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    958\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    962\u001b[39m     **kwargs: Any,\n\u001b[32m    963\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    964\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_ollama/chat_models.py:1054\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m   1048\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1049\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   1050\u001b[39m     stop: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1051\u001b[39m     **kwargs: Any,\n\u001b[32m   1052\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m   1053\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1060\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_ollama/chat_models.py:952\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    951\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m--> \u001b[39m\u001b[32m952\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mchat_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m    954\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/ollama/_client.py:372\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, logprobs, top_logprobs, format, options, keep_alive)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    319\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    320\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    331\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    332\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    334\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    363\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m    365\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m    366\u001b[39m     ChatResponse,\n\u001b[32m    367\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    368\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m/api/chat\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    369\u001b[39m     json=ChatRequest(\n\u001b[32m    370\u001b[39m       model=model,\n\u001b[32m    371\u001b[39m       messages=\u001b[38;5;28mlist\u001b[39m(_copy_messages(messages)),\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m       tools=\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    373\u001b[39m       stream=stream,\n\u001b[32m    374\u001b[39m       think=think,\n\u001b[32m    375\u001b[39m       logprobs=logprobs,\n\u001b[32m    376\u001b[39m       top_logprobs=top_logprobs,\n\u001b[32m    377\u001b[39m       \u001b[38;5;28mformat\u001b[39m=\u001b[38;5;28mformat\u001b[39m,\n\u001b[32m    378\u001b[39m       options=options,\n\u001b[32m    379\u001b[39m       keep_alive=keep_alive,\n\u001b[32m    380\u001b[39m     ).model_dump(exclude_none=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    381\u001b[39m     stream=stream,\n\u001b[32m    382\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/ollama/_client.py:1293\u001b[39m, in \u001b[36m_copy_tools\u001b[39m\u001b[34m(tools)\u001b[39m\n\u001b[32m   1291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_copy_tools\u001b[39m(tools: Optional[Sequence[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Tool, Callable]]] = \u001b[38;5;28;01mNone\u001b[39;00m) -> Iterator[Tool]:\n\u001b[32m   1292\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m unprocessed_tool \u001b[38;5;129;01min\u001b[39;00m tools \u001b[38;5;129;01mor\u001b[39;00m []:\n\u001b[32m-> \u001b[39m\u001b[32m1293\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m convert_function_to_tool(unprocessed_tool) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(unprocessed_tool) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mTool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed_tool\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/pydantic/main.py:716\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, extra, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    712\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    713\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    714\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Tool\n  Input should be a valid dictionary or instance of Tool [type=model_type, input_value=StructuredTool(name='rag_...tool at 0x7daf25637ba0>), input_type=StructuredTool]\n    For further information visit https://errors.pydantic.dev/2.12/v/model_type",
      "During task with name 'chat_node' and id '3176e345-a11e-ca13-1a3b-b2b1d525f520'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "thread_id = \"1\"\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "\n",
    "    result = chatbot.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "\n",
    "    print(\"Bot:\", result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28d35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
