{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4f63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import TypedDict, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a1d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded. AIzaSyDgn1GTu164ppUpDjewi3HG66JK5ui6y78\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "print(\"Environment variables loaded.\", os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=400,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fbc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = Field(\n",
    "        description=\"The sentiment of the review\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f84feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\" , \"Other\"] = Field(\"The category of the issue mentioned in the review\")\n",
    "    tone: Literal[\"Formal\", \"Informal\", \"Friendly\", \"Apologetic\", \"Promotional\"] = Field(\"the tone expressed by the user\")\n",
    "    urgency: Literal[\"High\", \"Medium\", \"Low\"] = Field(\"how urgent the reply should be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a81eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = model.with_structured_output(SentimentSchema)\n",
    "diagnosis_model = model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c6c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewInput(TypedDict , total= False):\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c844444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewInput) -> dict:\n",
    "    prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = sentiment_model.invoke(prompt).sentiment\n",
    "\n",
    "    return {'sentiment': sentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419062e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_diagnosis(state: ReviewInput) -> dict:\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "\"\"\"\n",
    "    response = diagnosis_model.invoke(prompt)\n",
    "\n",
    "    return {'diagnosis': response.model_dump()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2950949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_response(state: ReviewInput) -> dict:\n",
    "    prompt = f\"\"\"Write a warm thank-you message in response to this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "Also, kindly ask the user to leave feedback on our website.\"\"\"\n",
    "    \n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da459337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_response(state: ReviewInput) -> dict:\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd77253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentiment(state: ReviewInput) -> str:\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1976bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x74aa6f495a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(ReviewInput)\n",
    "\n",
    "# add node\n",
    "graph.add_node(\"find_sentiment\", find_sentiment)\n",
    "graph.add_node(\"run_diagnosis\", run_diagnosis)\n",
    "graph.add_node(\"positive_response\", positive_response)\n",
    "graph.add_node(\"negative_response\", negative_response)\n",
    "\n",
    "# add edges\n",
    "graph.add_edge(START, \"find_sentiment\")\n",
    "graph.add_conditional_edges(\n",
    "    \"find_sentiment\",\n",
    "    check_sentiment,\n",
    "    {\n",
    "        \"positive_response\": \"positive_response\",\n",
    "        \"run_diagnosis\": \"run_diagnosis\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "graph.add_edge(\"positive_response\", END)\n",
    "graph.add_edge(\"run_diagnosis\", \"negative_response\")\n",
    "graph.add_edge(\"negative_response\", END)\n",
    "\n",
    "workflow = graph.compile()\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587f0e69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-flash-lite' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.642021747s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:3047\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/google/genai/models.py:5215\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5214\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5215\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5217\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5219\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/google/genai/models.py:3997\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3995\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3997\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4002\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4003\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/google/genai/_api_client.py:1386\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1383\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1384\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1385\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m response_body = (\n\u001b[32m   1388\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1389\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/google/genai/_api_client.py:1220\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1219\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/google/genai/_api_client.py:1199\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1192\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1193\u001b[39m     method=http_request.method,\n\u001b[32m   1194\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1197\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1198\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1201\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1202\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/google/genai/errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/google/genai/errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.642021747s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m intial_state={\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mIâ€™ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mfind_sentiment\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_sentiment\u001b[39m(state: ReviewInput) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m      2\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFor the following review find out the sentiment \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m\"\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     sentiment = \u001b[43msentiment_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m.sentiment\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m: sentiment}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3149\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3149\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3150\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3151\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5557\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5550\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5555\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5556\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5558\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5560\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:2535\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2532\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2533\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:3051\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3048\u001b[39m         **request,\n\u001b[32m   3049\u001b[39m     )\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3051\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Agentic/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-2.5-flash-lite' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.642021747s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}",
      "During task with name 'find_sentiment' and id '1ab9d299-b35c-c1c2-eeb1-bef69b408835'"
     ]
    }
   ],
   "source": [
    "intial_state={\n",
    "    'review': \"Iâ€™ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\"\n",
    "}\n",
    "workflow.invoke(intial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
